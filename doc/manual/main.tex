%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% cuRAMSES-kjhan Technical Reference Manual
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%    PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[11pt,fleqn]{book}

\usepackage[top=3cm,bottom=3cm,left=3.2cm,right=3.2cm,headsep=10pt,headheight=14pt,a4paper]{geometry}

\usepackage{xcolor}
\definecolor{ocre}{RGB}{52,177,201}

% Font Settings
\usepackage{avant}
\usepackage{mathptmx}
\usepackage{microtype}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

% Bibliography
\usepackage[style=alphabetic,sorting=nyt,sortcites=true,autopunct=true,hyperref=true,abbreviate=false,backref=true,backend=biber]{biblatex}
\addbibresource{bibliography.bib}
\defbibheading{bibempty}{}

\input{structure}

%----------------------------------------------------------------------------------------
%    Definitions of new commands
%----------------------------------------------------------------------------------------

\def\R{\mathbb{R}}

%------------------------------------------------------
% Document
%------------------------------------------------------
\begin{document}

%------------------------------------------------------
% Title page
%------------------------------------------------------
\begin{titlepage}
\begin{tikzpicture}[remember picture,overlay]
  % Top colored area
  \fill[ocre] (current page.north west) rectangle ([yshift=-9cm]current page.north east);
  % Bottom accent strip
  \fill[ocre!10] (current page.south west) rectangle ([yshift=2.5cm]current page.south east);
  \draw[ocre,line width=1.5pt] ([yshift=2.5cm]current page.south west) -- ([yshift=2.5cm]current page.south east);
\end{tikzpicture}

\vspace*{1cm}

\begin{center}
{\fontsize{42}{50}\selectfont\sffamily\bfseries\color{white}cuRAMSES-kjhan}\\[1cm]
{\fontsize{20}{24}\selectfont\sffamily\color{white!80}Technical Reference Manual}
\end{center}

\vspace{5cm}

\begin{center}
{\Large\sffamily
K-Section Ordering, Morton Key Octree,\\[8pt]
Memory-Based Load Balancing, and\\[8pt]
Performance Optimizations}

\vspace{3cm}

{\large\sffamily Jaehyun~Han}\\[0.5cm]
{\sffamily February 2026}
\end{center}

\vfill

\begin{center}
{\small\sffamily
Based on RAMSES (R.~Teyssier)\\[3pt]
\texttt{git@github.com:kjhan0606/cuRAMSES-kjhan.git}}
\end{center}
\vspace{1cm}
\end{titlepage}

%------------------------------------------------------
% Table of Contents
%------------------------------------------------------

\pagestyle{empty}
\tableofcontents
\pagestyle{fancy}

%------------------------------------------------------
% PART I: Modifications Overview
%------------------------------------------------------
\part{Code Modifications}

%======================================================
\chapter{K-Section Ordering}
%======================================================

\section{Overview}

The \textbf{k-section ordering} replaces the standard Hilbert curve domain decomposition with a hierarchical spatial bisection tree. Unlike the Hilbert curve approach that relies on a 1D space-filling curve, the k-section ordering partitions the 3D domain using recursive bisection along each coordinate axis, producing a balanced k-ary tree of spatial subdomains.

\begin{infobox}[Key Advantage]
The k-section tree enables \textbf{hierarchical MPI exchange} where communication follows the tree structure, achieving $O(\sum k_l)$ messages per exchange instead of $O(N_{\text{cpu}})$ all-to-all communication.
\end{infobox}

\section{Hierarchical MPI Exchange}

Two exchange routines are provided in \texttt{patch/cuda/ksection.f90}:

\begin{itemize}[leftmargin=2em]
  \item \texttt{ksection\_exchange\_dp} --- exclusive exchange (each item $\to$ exactly 1 destination CPU)
  \item \texttt{ksection\_exchange\_dp\_overlap} --- overlap exchange (items routed by spatial bounding box)
\end{itemize}

\subsection{Exclusive Exchange}

Each data item has a known destination CPU. The algorithm performs level-by-level correspondent exchange through the k-section tree, using MPI tags 100--300+level.

\subsection{Overlap Exchange}

Items have spatial extent (bounding box) and may need to reach multiple CPUs. The tree walk determines all destination CPUs whose spatial domain overlaps the item's bounding box. MPI tags 400--500+level are used.

\subsection{Periodic Boundary Conditions}

The optional \texttt{periodic=.true.} parameter enables handling of items that wrap around the domain boundary $[0, \text{scale}]$. For each wrapping dimension, $2^{n_{\text{wrap}}}-1$ shifted copies are generated via bitmask subset enumeration before the tree walk.

\section{Tree Navigation}

The arrays \texttt{ksec\_cpumin/cpumax} and \texttt{ksec\_cpu\_path} (set in \texttt{build\_ksection} and at restart via \texttt{rebuild\_ksec\_cpuranges}) enable each CPU to navigate the tree efficiently.

\section{Verification}

The exchange routines are tested in \texttt{test\_ksection\_exchange} with 4 test cases:
\begin{enumerate}
  \item Exclusive point exchange
  \item Overlap point exchange
  \item Full overlap exchange
  \item Periodic overlap exchange (20\% radius items)
\end{enumerate}
All tests pass.


%======================================================
\chapter{Ghost Zone Exchange via K-Section}
%======================================================

\section{AMR Ghost Zones}

The standard RAMSES ghost zone exchange uses \texttt{MPI\_ISEND/IRECV} with all-to-all communication patterns. This was replaced with k-section tree-routed exchange for the \texttt{ordering='ksection'} mode.

\subsection{Modified File}

\texttt{patch/cuda/virtual\_boundaries.kjhan.f90}

\subsection{Subroutines}

Four k-section variants were implemented:

\begin{center}
\begin{tabular}{lll}
\toprule
\textbf{Subroutine} & \textbf{Direction} & \textbf{Data Type} \\
\midrule
\texttt{make\_virtual\_fine\_dp\_ksec} & Forward & \texttt{real(dp)} \\
\texttt{make\_virtual\_fine\_int\_ksec} & Forward & \texttt{integer} \\
\texttt{make\_virtual\_reverse\_dp\_ksec} & Reverse (+= accumulate) & \texttt{real(dp)} \\
\texttt{make\_virtual\_reverse\_int\_ksec} & Reverse (+= accumulate) & \texttt{integer} \\
\bottomrule
\end{tabular}
\end{center}

\subsection{Data Packing}

Each emission grid is packed as:
\[
\texttt{sendbuf}(1{:}\text{twotondim}+2,\; i) = \bigl[\underbrace{c_1, c_2, \ldots, c_8}_{\text{cell data}},\; \underbrace{\text{myid}}_{\text{sender}},\; \underbrace{i}_{\text{index}}\bigr]
\]

The metadata (sender ID, emission index) allows the receiver to scatter data to the correct reception grid without requiring a priori knowledge of the communication pattern.

\subsection{Dispatch}

Dispatch is automatic via:
\begin{lstlisting}[style=fortran,numbers=none]
if(ordering=='ksection') then
   call make_virtual_fine_dp_ksec(xx, ilevel)
   return
end if
\end{lstlisting}

\subsection{Bulk Exchange}

Four bulk variants exchange all columns of a 2D array (e.g., \texttt{uold}, \texttt{f}, \texttt{unew}) in a single \texttt{ksection\_exchange\_dp} call:

\begin{center}
\begin{tabular}{ll}
\toprule
\textbf{Subroutine} & \textbf{Description} \\
\midrule
\texttt{make\_virtual\_fine\_dp\_bulk} & Forward bulk exchange \\
\texttt{make\_virtual\_fine\_dp\_bulk\_ksec} & Forward bulk (ksection impl.) \\
\texttt{make\_virtual\_reverse\_dp\_bulk} & Reverse bulk exchange \\
\texttt{make\_virtual\_reverse\_dp\_bulk\_ksec} & Reverse bulk (ksection impl.) \\
\bottomrule
\end{tabular}
\end{center}

Buffer layout for \texttt{ncols} variables:
\[
\texttt{sendbuf}\bigl((v{-}1) \cdot 2^{3} + j,\;\text{idx}\bigr) = \texttt{xx}(\text{icell},\; v) \quad v=1{\ldots}\text{ncols},\; j=1{\ldots}8
\]
plus 2 metadata words (sender ID, index). This reduces MPI exchanges from $N_{\text{var}}$ per level to 1 per array.

\section{build\_comm via K-Section}

The \texttt{build\_comm} subroutine's \texttt{MPI\_ALLTOALL} + \texttt{MPI\_ISEND/IRECV} pattern was also replaced with \texttt{ksection\_exchange\_dp}.

\section{MPI\_ALLTOALL Replacements}

Additional \texttt{MPI\_ALLTOALL} calls in the following files were replaced with k-section exchange:
\begin{itemize}[leftmargin=2em]
  \item \texttt{particle\_tree.kjhan.f90}
  \item \texttt{init\_part.f90}
  \item \texttt{multigrid\_fine\_commons.f90} (in \texttt{build\_parent\_comms\_mg})
\end{itemize}

\section{Pre-Allocated Buffer Pool}

Per-level small arrays (child count, peer list, MPI requests) were converted to \texttt{save} variables to eliminate ${\sim}100$ allocations/deallocations per call. The \texttt{peer\_recv} buffer uses grow-only capacity, and the first dimension must exactly match \texttt{nprops} for MPI stride correctness.


%======================================================
\chapter{Multigrid Poisson K-Section Communication}
%======================================================

\section{Motivation}

The multigrid Poisson solver (\texttt{poisson-mg}) accounts for 29--41\% of total runtime. The original MPI communication used \texttt{MPI\_ISEND/IRECV} with all-to-all patterns across all CPUs.

\section{Implementation}

Four k-section variants were added to \texttt{patch/cuda/multigrid\_fine\_commons.f90}:

\begin{center}
\begin{tabular}{lll}
\toprule
\textbf{Subroutine} & \textbf{Direction} & \textbf{Data Type} \\
\midrule
\texttt{make\_virtual\_mg\_dp\_ksec} & Forward & \texttt{real(dp)} \\
\texttt{make\_virtual\_mg\_int\_ksec} & Forward & \texttt{integer} \\
\texttt{make\_reverse\_mg\_dp\_ksec} & Reverse (+= accumulate) & \texttt{real(dp)} \\
\texttt{make\_reverse\_mg\_int\_ksec} & Reverse (+= accumulate) & \texttt{integer} \\
\bottomrule
\end{tabular}
\end{center}

\subsection{Key Differences from AMR Exchange}

The MG communication uses different data structures from the standard AMR exchange:

\begin{center}
\begin{tabular}{lll}
\toprule
\textbf{Aspect} & \textbf{AMR} & \textbf{Multigrid} \\
\midrule
Active grids & \texttt{active(ilevel)} & \texttt{active\_mg(myid,ilevel)} \\
Reception & \texttt{reception(icpu,ilevel)} & \texttt{active\_mg(icpu,ilevel)} \\
Emission & \texttt{emission(icpu,ilevel)} & \texttt{emission\_mg(icpu,ilevel)} \\
Data arrays & \texttt{xx(igrid+iskip)} & \texttt{active\_mg\%u(icell,ivar)} \\
Indexing & Global grid index & Local offset in active\_mg \\
\bottomrule
\end{tabular}
\end{center}

\subsection{Forward Exchange}

\begin{enumerate}
  \item Pack: for each \texttt{emission\_mg(icpu)\%igrid(i)}, gather \texttt{twotondim} values from \texttt{active\_mg(myid)\%u} + metadata (sender\_id, index)
  \item Exchange via \texttt{ksection\_exchange\_dp}
  \item Scatter: use metadata to write into \texttt{active\_mg(sender)\%u(ridx + step, ivar)}
\end{enumerate}

\subsection{Reverse Exchange (Accumulation)}

\begin{enumerate}
  \item Pack: for each remote \texttt{active\_mg(icpu)\%u(i + step, ivar)} + metadata
  \item Exchange via \texttt{ksection\_exchange\_dp}
  \item Accumulate: \texttt{active\_mg(myid)\%u(emission\_mg(sender)\%igrid(ridx) + step, ivar) += recvbuf}
\end{enumerate}


%======================================================
\chapter{Morton Key Octree}
%======================================================

\section{Overview}

The \texttt{nbor} array (6 neighbor pointers per grid) was replaced with a Morton key hash table for $O(1)$ neighbor lookup. This saves $6 \times 8 \times N_{\text{gridmax}}$ bytes of memory.

\subsection{Modified Files}

\begin{itemize}[leftmargin=2em]
  \item \texttt{patch/oct\_tree/morton\_keys.f90} --- Morton key computation
  \item \texttt{patch/oct\_tree/morton\_hash.f90} --- Hash table and helper functions
  \item \texttt{patch/oct\_tree/morton\_init.f90} --- Initialization and verification
  \item \texttt{patch/oct\_tree/refine\_utils.f90} --- Hash table maintenance
  \item \texttt{patch/oct\_tree/nbors\_utils.kjhan.f90} --- Neighbor lookup functions
\end{itemize}

\section{Morton Key}

A 64-bit Morton key is computed by interleaving the 3D integer coordinates (21 bits per dimension):
\[
\text{key} = \text{interleave}\bigl(\lfloor x_g \cdot 2^{l-1} \rfloor,\; \lfloor y_g \cdot 2^{l-1} \rfloor,\; \lfloor z_g \cdot 2^{l-1} \rfloor\bigr)
\]

\section{Hash Table}

A per-level open-addressing hash table with linear probing and power-of-2 capacity maps Morton keys to grid indices. The table is maintained in \texttt{make\_grid\_coarse/fine} and \texttt{kill\_grid}, with a full rebuild after each time step.

\section{Neighbor Lookup}

Two helper functions in the \texttt{morton\_hash} module:
\begin{itemize}[leftmargin=2em]
  \item \texttt{morton\_nbor\_grid(igrid, ilevel, j)} --- returns \texttt{son(nbor(igrid,j))} equivalent
  \item \texttt{morton\_nbor\_cell(igrid, ilevel, j)} --- returns \texttt{nbor(igrid,j)} equivalent
\end{itemize}

Direction convention: $j = 1{:}{-x},\; 2{:}{+x},\; 3{:}{-y},\; 4{:}{+y},\; 5{:}{-z},\; 6{:}{+z}$.

\section{nbor Array Removal (Phase 4)}

The \texttt{nbor} array is allocated as \texttt{allocate(nbor(1:1,1:1))} (minimum size to avoid compilation errors). All code paths use Morton lookup exclusively.


%======================================================
\chapter{Memory-Based Load Balancing}
%======================================================

\section{Motivation}

Standard RAMSES load balancing distributes cells evenly across CPUs, but cells with many particles consume significantly more memory. Memory-based balancing weights each cell by its memory footprint.

\section{Cost Function}

\[
\text{cell\_cost} = \frac{\texttt{mem\_weight\_grid}}{\text{twotondim}} + \text{numbp}(\text{igrid}) \times \frac{\texttt{mem\_weight\_part}}{\text{twotondim}}
\]

where:
\begin{itemize}[leftmargin=2em]
  \item \texttt{mem\_weight\_grid} = 270 (default) --- memory per grid in dp-equivalents
  \item \texttt{mem\_weight\_part} = 12 (default) --- memory per particle in dp-equivalents
\end{itemize}

\section{Implementation Details}

\begin{itemize}[leftmargin=2em]
  \item All histogram variables use 64-bit integers (\texttt{integer(i8b)}) with \texttt{MPI\_INTEGER8}
  \item \texttt{numbp} is synchronized for virtual/reception grids before cost computation, then restored afterwards
  \item The \texttt{numbp} restore uses a save/restore pattern to avoid breaking the particle tree
\end{itemize}

\section{Parameters}

Controlled by three namelist parameters in \texttt{\&RUN\_PARAMS}:
\begin{itemize}[leftmargin=2em]
  \item \texttt{memory\_balance = .true.} --- enable memory-based balancing
  \item \texttt{mem\_weight\_grid = 270} --- grid memory weight
  \item \texttt{mem\_weight\_part = 12} --- particle memory weight
\end{itemize}


%======================================================
\chapter{Memory Savings: Large Array Optimization}
%======================================================

\section{Overview}

Several large arrays were eliminated or converted to on-demand allocation to reduce steady-state memory usage by ${\sim}960$\,MB (for \texttt{ngridmax}=5M).

\begin{center}
\begin{tabular}{llr}
\toprule
\textbf{Array} & \textbf{Strategy} & \textbf{Savings} \\
\midrule
\texttt{hilbert\_key} & \texttt{allocate(1:1)} for ksection & ${\sim}640$\,MB \\
\texttt{bisec\_ind\_cell} + \texttt{cell\_level} & On-demand alloc/dealloc & ${\sim}320$\,MB \\
\texttt{defrag\_map} & Local scratch during defrag & minor \\
\texttt{nbor} & \texttt{allocate(1:1,1:1)} (Morton) & ${\sim}240$\,MB \\
\bottomrule
\end{tabular}
\end{center}


%======================================================
\chapter{IC Reading with Stream Access}
%======================================================

\section{Motivation}

Sequential Fortran I/O requires reading all preceding planes to reach a target plane, which is $O(n^2)$ for large files. Stream access enables direct byte-offset seeks.

\section{Implementation}

Fortran 2003 \texttt{ACCESS='STREAM'} is used with computed byte offsets:

\begin{lstlisting}[style=fortran,numbers=none]
hdr_bytes = 52 + (i3-1)*plane_bytes + 5
plane_bytes = n1*n2*4 + 8  ! data + 2 record markers
\end{lstlisting}

Applied to hydro IC (deltab, velocity, temperature), particle velocity and position files. Only for \texttt{multiple=.false.} mode.

\subsection{Modified Files}
\begin{itemize}[leftmargin=2em]
  \item \texttt{patch/Horizon5-master-2/init\_flow\_fine.f90}
  \item \texttt{init\_part.f90}
\end{itemize}


%======================================================
\chapter{Load Balance Profiling and Tuning}
%======================================================

\section{Internal Timing}

Detailed timing breakdown was added to \texttt{load\_balance} in \texttt{patch/cuda/load\_balance.kjhan.f90}:

\begin{center}
\begin{tabular}{llr}
\toprule
\textbf{Section} & \textbf{Description} & \textbf{Typical (s/step)} \\
\midrule
\texttt{numbp\_sync} & MPI sync of numbp for virtual grids & 0.8--1.0 \\
\texttt{cmp\_new\_cpu\_map} & Build ksection + compute new map & 0.4--0.6 \\
\texttt{expand\_pass} & build\_comm + make\_virtual loop & 0.8--1.5 \\
\texttt{grid\_migration} & Linked-list reconnection & $< 0.01$ \\
\texttt{allreduce+cpumap\_update} & MPI\_ALLREDUCE $\times$4 + cpu\_map & 2.3--3.3 \\
\texttt{shrink\_pass} & flag\_fine + build\_comm loop & 0.4--1.0 \\
\bottomrule
\end{tabular}
\end{center}

\section{nremap Tuning}

The \texttt{nremap} parameter controls load balancing frequency (every $N$ coarse steps). Testing with 200M particles on 12 ranks showed:

\begin{center}
\begin{tabular}{rrrrl}
\toprule
\textbf{nremap} & \textbf{Total (s)} & \textbf{Loadbal (s)} & \textbf{Speedup} & \textbf{Note} \\
\midrule
1 & 303.8 & 64.4 (21.2\%) & --- & Baseline \\
3 & 269.9 & 24.7 (9.1\%) & 1.13$\times$ & \\
5 & 249.8 & 15.7 (6.3\%) & \textbf{1.22$\times$} & \textbf{Optimal} \\
10 & 258.6 & 11.6 (4.5\%) & 1.17$\times$ & Imbalance grows \\
\bottomrule
\end{tabular}
\end{center}

\begin{infobox}[Default Setting]
\texttt{nremap=5} is set as the default. All four configurations produce \textbf{bit-identical} results: \texttt{econs=3.77E-03}, \texttt{epot=-1.88E-06}, \texttt{ekin=1.23E-06} at step 10.
\end{infobox}

\section{Min/Max Memory Reporting}

The \texttt{writemem\_minmax} subroutine prints per-step min/max memory usage across all MPI ranks.


%------------------------------------------------------
% PART II: Namelist Reference
%------------------------------------------------------
\part{Namelist Reference}

%======================================================
\chapter{RUN\_PARAMS}
%======================================================

Runtime control parameters.

\begin{longtable}{L{3.5cm} C{1.8cm} C{1.8cm} L{6cm}}
\toprule
\textbf{Parameter} & \textbf{Type} & \textbf{Default} & \textbf{Description} \\
\midrule
\endhead
\texttt{cosmo} & logical & \texttt{.false.} & Enable cosmological simulation \\
\texttt{pic} & logical & \texttt{.false.} & Enable Particle-In-Cell \\
\texttt{poisson} & logical & \texttt{.false.} & Enable Poisson gravity solver \\
\texttt{hydro} & logical & \texttt{.false.} & Enable hydrodynamics \\
\texttt{rt} & logical & \texttt{.false.} & Enable radiative transfer \\
\texttt{sink} & logical & \texttt{.false.} & Enable sink particles \\
\texttt{verbose} & logical & \texttt{.false.} & Verbose output \\
\texttt{debug} & logical & \texttt{.false.} & Debug mode \\
\midrule
\texttt{nrestart} & integer & 0 & Restart file number (0 = new run) \\
\texttt{nstepmax} & integer & 1000000 & Maximum number of coarse steps \\
\texttt{ncontrol} & integer & 1 & Frequency of control variable output \\
\texttt{nsubcycle} & integer[] & 2 & Subcycling factor per level \\
\texttt{nremap} & integer & \textbf{5} & Load balancing frequency (0=never) \\
\texttt{ordering} & char & \texttt{hilbert} & Domain decomposition: \texttt{hilbert}, \texttt{bisection}, \texttt{ksection} \\
\texttt{static} & logical & \texttt{.false.} & Static (no refinement) mode \\
\texttt{overload} & integer & 1 & MPI overload factor \\
\texttt{cost\_weighting} & logical & \texttt{.true.} & CPU time-based cost weighting \\
\midrule
\multicolumn{4}{l}{\textit{Memory-based load balancing (new)}} \\
\midrule
\texttt{memory\_balance} & logical & \texttt{.false.} & Enable memory-weighted balancing \\
\texttt{mem\_weight\_grid} & integer & 270 & Memory per grid (dp-equivalents) \\
\texttt{mem\_weight\_part} & integer & 12 & Memory per particle (dp-equivalents) \\
\bottomrule
\end{longtable}


%======================================================
\chapter{AMR\_PARAMS}
%======================================================

Adaptive Mesh Refinement grid parameters.

\begin{longtable}{L{3.5cm} C{1.8cm} C{1.8cm} L{6cm}}
\toprule
\textbf{Parameter} & \textbf{Type} & \textbf{Default} & \textbf{Description} \\
\midrule
\endhead
\texttt{levelmin} & integer & 1 & Minimum (uniform) refinement level \\
\texttt{levelmax} & integer & 1 & Maximum refinement level \\
\texttt{ngridmax} & integer8 & 0 & Max grids per CPU (0 = auto) \\
\texttt{ngridtot} & integer8 & 0 & Total grids for auto-computation \\
\texttt{npartmax} & integer & 0 & Max particles per CPU (0 = auto) \\
\texttt{nparttot} & integer & 0 & Total particles for auto-computation \\
\texttt{nexpand} & integer[] & 1 & Mesh expansion layers per level \\
\texttt{boxlen} & real(dp) & 1.0 & Box side length in code units \\
\bottomrule
\end{longtable}


%======================================================
\chapter{OUTPUT\_PARAMS}
%======================================================

Output control parameters.

\begin{longtable}{L{3.5cm} C{1.8cm} C{1.8cm} L{6cm}}
\toprule
\textbf{Parameter} & \textbf{Type} & \textbf{Default} & \textbf{Description} \\
\midrule
\endhead
\texttt{noutput} & integer & 1 & Number of scheduled outputs \\
\texttt{foutput} & integer & 1000000 & Output every $N$ steps \\
\texttt{fbackup} & integer & 1000000 & Backup every $N$ steps \\
\texttt{aout} & real[] & 1.1 & Output expansion factors (cosmo) \\
\texttt{tout} & real[] & 0.0 & Output times (non-cosmo) \\
\texttt{output\_mode} & integer & 0 & Hi-res output mode \\
\texttt{gadget\_output} & logical & \texttt{.false.} & Write Gadget-format snapshots \\
\texttt{walltime\_hrs} & real(dp) & $-1$ & Job walltime (hours, $<0$ = ignore) \\
\texttt{minutes\_dump} & real(dp) & 1.0 & Dump this many minutes before walltime \\
\bottomrule
\end{longtable}


%======================================================
\chapter{INIT\_PARAMS}
%======================================================

Initial conditions parameters.

\begin{longtable}{L{3.5cm} C{1.8cm} C{1.8cm} L{6cm}}
\toprule
\textbf{Parameter} & \textbf{Type} & \textbf{Default} & \textbf{Description} \\
\midrule
\endhead
\texttt{filetype} & char(20) & \texttt{ascii} & IC file format: \texttt{ascii}, \texttt{grafic}, \texttt{gadget} \\
\texttt{initfile} & char[] & \texttt{' '} & IC file path per level \\
\texttt{multiple} & logical & \texttt{.false.} & Multiple IC files per rank \\
\texttt{nregion} & integer & 0 & Number of IC regions \\
\bottomrule
\end{longtable}


%======================================================
\chapter{REFINE\_PARAMS}
%======================================================

Refinement criteria parameters.

\begin{longtable}{L{3.5cm} C{1.8cm} C{1.8cm} L{6cm}}
\toprule
\textbf{Parameter} & \textbf{Type} & \textbf{Default} & \textbf{Description} \\
\midrule
\endhead
\texttt{m\_refine} & real[] & $-1$ & Lagrangian mass threshold per level \\
\texttt{ivar\_refine} & integer & $-1$ & Variable index for gradient refinement \\
\texttt{var\_cut\_refine} & real(dp) & $-1$ & Variable threshold \\
\texttt{mass\_cut\_refine} & real(dp) & $-1$ & Particle mass threshold \\
\texttt{interpol\_var} & integer & 0 & Interpolation variable (0=conservative, 1=primitive) \\
\texttt{interpol\_type} & integer & 1 & Interpolation type (0=MinMod, 1=MonCen) \\
\texttt{sink\_refine} & logical & \texttt{.false.} & Fully refine around sinks \\
\texttt{jeans\_ncells} & real(dp) & $-1$ & Jeans length in cells ($>0$ enables polytropic EOS) \\
\bottomrule
\end{longtable}


%======================================================
\chapter{HYDRO\_PARAMS}
%======================================================

Hydrodynamics solver parameters.

\begin{longtable}{L{3.5cm} C{1.8cm} C{1.8cm} L{6cm}}
\toprule
\textbf{Parameter} & \textbf{Type} & \textbf{Default} & \textbf{Description} \\
\midrule
\endhead
\texttt{gamma} & real(dp) & $\frac{5}{3}$ & Adiabatic index $\gamma$ \\
\texttt{courant\_factor} & real(dp) & 0.8 & Courant--Friedrichs--Lewy number \\
\texttt{scheme} & char(20) & \texttt{muscl} & Hydro scheme (\texttt{muscl}) \\
\texttt{slope\_type} & integer & 1 & Slope limiter (1=MinMod, 2=MonCen, 3=unlimited) \\
\texttt{pressure\_fix} & logical & \texttt{.false.} & Pressure floor for strong shocks \\
\texttt{beta\_fix} & real(dp) & 0.0 & Pressure fix strength \\
\texttt{isothermal} & logical & \texttt{.false.} & Isothermal mode \\
\bottomrule
\end{longtable}


%======================================================
\chapter{POISSON\_PARAMS}
%======================================================

Gravity and Poisson solver parameters.

\begin{longtable}{L{3.5cm} C{1.8cm} C{1.8cm} L{6cm}}
\toprule
\textbf{Parameter} & \textbf{Type} & \textbf{Default} & \textbf{Description} \\
\midrule
\endhead
\texttt{epsilon} & real(dp) & $10^{-4}$ & Multigrid convergence criterion \\
\texttt{gravity\_type} & integer & 0 & Gravity type (0=self-gravity, $>0$=analytic) \\
\texttt{cg\_levelmin} & integer & 999 & Min level for CG solver fallback \\
\texttt{cic\_levelmax} & integer & 0 & Max level for CIC particle interpolation \\
\bottomrule
\end{longtable}


%======================================================
\chapter{PHYSICS\_PARAMS}
%======================================================

Subgrid physics parameters (star formation, feedback, cooling).

\begin{longtable}{L{3.5cm} C{1.8cm} C{2cm} L{5.5cm}}
\toprule
\textbf{Parameter} & \textbf{Type} & \textbf{Default} & \textbf{Description} \\
\midrule
\endhead
\texttt{cooling} & logical & \texttt{.false.} & Enable radiative cooling \\
\texttt{metal} & logical & \texttt{.false.} & Enable metal tracking \\
\texttt{haardt\_madau} & logical & \texttt{.false.} & UV background \\
\texttt{z\_reion} & real(dp) & 8.5 & Reionization redshift \\
\midrule
\multicolumn{4}{l}{\textit{Star formation}} \\
\midrule
\texttt{n\_star} & real(dp) & 0.1 & SF density threshold (H/cc) \\
\texttt{t\_star} & real(dp) & 0.0 & SF timescale (Gyr) \\
\texttt{eps\_star} & real(dp) & 0.0 & SF efficiency \\
\texttt{T2\_star} & real(dp) & 0.0 & ISM polytropic temperature \\
\texttt{g\_star} & real(dp) & 1.6 & ISM polytropic index \\
\texttt{sf\_birth\_properties} & logical & \texttt{.true.} & Output stellar birth properties \\
\midrule
\multicolumn{4}{l}{\textit{Cosmology (read from IC header or namelist)}} \\
\midrule
\texttt{omega\_b} & real(dp) & 0.0 & Baryon density $\Omega_b$ \\
\texttt{omega\_m} & real(dp) & 1.0 & Matter density $\Omega_m$ \\
\texttt{omega\_l} & real(dp) & 0.0 & Dark energy $\Omega_\Lambda$ \\
\texttt{h0} & real(dp) & 1.0 & Hubble constant $H_0$ (km/s/Mpc) \\
\midrule
\multicolumn{4}{l}{\textit{Feedback}} \\
\midrule
\texttt{f\_ek} & real(dp) & 1.0 & SN kinetic energy fraction \\
\texttt{rbubble} & real(dp) & 0.0 & SN superbubble radius (pc) \\
\texttt{yield\-table\-filename} & char & --- & Yield table file path \\
\bottomrule
\end{longtable}


%======================================================
\chapter{Example Namelist}
%======================================================

\section{Cosmological Simulation with Memory Balancing}

\begin{codebox}[cosmo\_ksection\_membal.nml]
\begin{lstlisting}[style=fortran,numbers=none]
&RUN_PARAMS
cosmo=.true.
pic=.true.
poisson=.true.
hydro=.true.
nrestart=0
nremap=5
nsubcycle=1,1,2
ncontrol=1
nstepmax=10
ordering='ksection'
memory_balance=.true.
/

&OUTPUT_PARAMS
noutput=1
aout=1.0
/

&INIT_PARAMS
filetype='grafic'
initfile(1)='/path/to/ics/level_008'
/

&AMR_PARAMS
levelmin=8
levelmax=10
nexpand=1
ngridtot=40000000
nparttot=200000000
/

&REFINE_PARAMS
m_refine=3*8.,
ivar_refine=0
interpol_var=1
interpol_type=0
/

&HYDRO_PARAMS
gamma=1.6666667
courant_factor=0.8
scheme='muscl'
slope_type=1
/

&POISSON_PARAMS
/

&PHYSICS_PARAMS
sf_birth_properties=.false.
yieldtablefilename='yield_table.asc'
/
\end{lstlisting}
\end{codebox}


%------------------------------------------------------
% PART III: Build and Testing
%------------------------------------------------------
\part{Build and Testing}

%======================================================
\chapter{Build Instructions}
%======================================================

\section{Prerequisites}

\begin{itemize}[leftmargin=2em]
  \item Intel Fortran Compiler (\texttt{ifx}) with MPI support (\texttt{mpiifx})
  \item OpenMP support (\texttt{-qopenmp})
\end{itemize}

\section{Build}

\begin{codebox}[Build Commands]
\begin{lstlisting}[style=bash,numbers=none]
cd bin
make clean
make
\end{lstlisting}
\end{codebox}

The binary is produced as \texttt{bin/ramses\_final3d}.

\section{Compile-Time Options}

Key preprocessor flags set in the Makefile:
\begin{center}
\begin{tabular}{ll}
\toprule
\textbf{Flag} & \textbf{Meaning} \\
\midrule
\texttt{-DNDIM=3} & Three-dimensional simulation \\
\texttt{-DNVECTOR=32} & Vector length for grid sweeps \\
\texttt{-DLONGINT} & 64-bit integer grid indices \\
\texttt{-DQUADHILBERT} & Quad-precision Hilbert keys \\
\texttt{-DNVAR=11} & Number of hydro variables \\
\texttt{-DNPRE=8} & Passive scalar variables \\
\bottomrule
\end{tabular}
\end{center}


%======================================================
\chapter{Verification Tests}
%======================================================

\section{Test Configuration}

\begin{center}
\begin{tabular}{ll}
\toprule
\textbf{Setting} & \textbf{Value} \\
\midrule
IC & MUSIC \texttt{level\_008} (GRAFIC2 format) \\
MPI ranks & 12 \\
Levels & 8--10 \\
Steps & 10 \\
Ordering & ksection \\
\bottomrule
\end{tabular}
\end{center}

\section{Reference Values (nremap=5)}

\begin{center}
\begin{tabular}{lrrrrr}
\toprule
\textbf{Test} & \textbf{nparttot} & \textbf{econs} & \textbf{epot} & \textbf{ekin} & \textbf{mcons} \\
\midrule
membal & 200M & 3.77E-03 & $-$1.88E-06 & 1.23E-06 & $-$1.84E-16 \\
nomembal & 80M & 3.77E-03 & $-$1.88E-06 & 1.23E-06 & $-$1.84E-16 \\
\bottomrule
\end{tabular}
\end{center}

\section{Running Tests}

\begin{codebox}[Membal Test]
\begin{lstlisting}[style=bash,numbers=none]
cd test_ksection/run_cosmo_membal
cp ../../bin/ramses_final3d .
mpirun -np 12 ./ramses_final3d \
    ../cosmo_ksection_membal.nml
\end{lstlisting}
\end{codebox}

Verify that at step 10: \texttt{econs=3.77E-03}, \texttt{epot=-1.88E-06}, \texttt{ekin=1.23E-06}.


%------------------------------------------------------
% Appendix
%------------------------------------------------------
\appendix

\chapter{Modified Files Summary}

\begin{longtable}{L{6.5cm} L{7cm}}
\toprule
\textbf{File} & \textbf{Modifications} \\
\midrule
\endhead
\multicolumn{2}{l}{\textit{patch/cuda/}} \\
\midrule
\texttt{amr\_parameters.jaehyun.f90} & Memory balance params, nremap=5 default \\
\texttt{amr\_commons.kjhan.f90} & grid\_level array, communicator type \\
\texttt{read\_params.jaehyun.f90} & Read new namelist params \\
\texttt{bisection.f90} & nc\_in parameter, 64-bit histograms \\
\texttt{ksection.f90} & K-section tree + exchange routines \\
\texttt{load\_balance.kjhan.f90} & numbp sync, bulk exchange, internal timing \\
\texttt{virtual\_boundaries.kjhan.f90} & Ksec ghost exchange + bulk + build\_comm \\
\texttt{multigrid\_fine\_commons.f90} & MG ksection communication \\
\texttt{init\_amr.f90} & Memory savings, Morton init \\
\texttt{update\_time.f90} & Memory reporting \\
\texttt{adaptive\_loop.jaehyun.f90} & writemem\_minmax, Morton rebuild, bulk exchange \\
\midrule
\multicolumn{2}{l}{\textit{patch/oct\_tree/}} \\
\midrule
\texttt{morton\_keys.f90} & Morton key computation \\
\texttt{morton\_hash.f90} & Hash table + neighbor helpers \\
\texttt{morton\_init.f90} & Build and verify \\
\texttt{refine\_utils.f90} & Hash maintenance in grid ops \\
\texttt{nbors\_utils.kjhan.f90} & Morton-based neighbor lookup \\
\midrule
\multicolumn{2}{l}{\textit{patch/Horizon5-master-2/}} \\
\midrule
\texttt{init\_flow\_fine.f90} & Stream access IC reading \\
\texttt{init\_part.f90} & Stream access particle IC \\
\texttt{particle\_tree.kjhan.f90} & MPI\_ALLTOALL $\to$ ksection \\
\texttt{amr\_step.jaehyun.f90} & Bulk virtual exchange \\
\bottomrule
\end{longtable}


\end{document}
